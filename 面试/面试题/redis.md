



1. redis的数据结构：

   1. 什么是跳表？https://mp.weixin.qq.com/s/Ok0laJMn4_OzL-LxPTHawQ

      1. 如果链表的结点数量非常多，我们就可以抽出更多的索引层级，每一层索引的结点数量都是低层索引的一半，删除和插入需要维护索引
      2. 程序中跳表采用的是双向链表，无论前后结点还是上下结点，都各有两个指针相互指向彼此。
      3. 程序中跳表的每一层首位各有一个空结点，左侧的空节点是负无穷大，右侧的空节点是正无穷大。

   2. 五种数据结 

   3. redisObject  

      ```
      typedef struct redisObject{
           //类型
           unsigned type:4;
           //编码
           unsigned encoding:4;
           //指向底层数据结构的指针
           void *ptr;
           //引用计数
           int refcount;
           //记录最后一次被程序访问的时间
           unsigned lru:22;
      }robj
      ```

      

2. redis的线程模型？文件事件处理器的结构包含 4 个部分：1.多个 socket（客户端连接），2.IO 多路复用程序（支持多个客户端连接的关键），3.文件事件分派器（将 socket 关联到相应的事件处理器）4.事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）---处理流程为：当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件 

3.  为啥 redis 单线程模型也能效率这么高？

   1. 第一，纯内存访问，`Redis`将所有数据放在内存中，内存的响应时长大约为100纳秒，这是Redis达到每秒万级别访问的重要基础。
   2. 第二，非阻塞`I/O`，`Redis`使用`epoll`作为`I/O`多路复用技术的实现，再加上`Redis`自身的事件处理模型将`epoll`中的连接、读写、关闭都转换为事件。
   3. 第三，单线程避免了线程切换和竞态产生的消耗。既然采用单线程就能达到如此高的性能，那么也不失为一种不错的选择，因为单线程能带来几个好处：第一，单线程可以简化数据结构和算法的实现。如果对高级编程语言熟悉的读者应该了解并发数据结构实现不但困难而且开发测试比较麻烦。第二，单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。
   
4. Redis是如何判断数据是否过期的呢？

   Redis  通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。 

5. 过期的数据的删除策略了解么？

   1. 惰性删除 ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
   2. 定期删除 ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

   但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期  key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。

   怎么解决这个问题呢？答案就是： Redis 内存淘汰机制。（不是很懂）

6. Redis 内存淘汰机制了解么？

   Redis 提供 6 种数据淘汰策略：

   1. volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
   2. volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
   3. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
   4. allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
   5. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
   6. **no-**eviction****：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

   4.0 版本后增加以下两种：

   1. volatile-lfu（least frequently used）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
   2. allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

7. Redis 持久化机制(怎么保证 Redis 挂掉之后再重启数据可以进行恢复)

   Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）

   1. 快照（snapshotting）持久化（RDB）：快照持久化是 Redis 默认采用的持久化方式，在 Redis.conf 配置文件中默认有此下配置：

      ```conf
      save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
      save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
      save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快
      ```

   2. AOF（append-only file）持久化：与快照持久化相比，AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：appendonly yes

      在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

      ```conf
      appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
      appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
      appendfsync no        #让操作系统决定何时进行同步
      ```

   3. **补充内容：AOF 重写**

      AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

      AOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。

      在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF  文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF  文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF  文件重写操作

8. 缓存穿透

   1. 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。
   2. 如何解决缓存穿透
      1. 缓存无效 key（感觉没用）
      2. 布隆过滤器

9.  缓存雪崩

   1. 实际上，缓存雪崩描述的就是这样一个简单的场景：缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。
   2. 有哪些解决办法？
      1. 针对 Redis 服务不可用的情况：
         1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
         2. 限流，避免同时处理大量的请求。
      2. 针对热点缓存失效的情况：
         1. 设置不同的失效时间比如随机设置缓存的失效时间。
         2. 缓存永不失效。

10. 如何保证缓存和数据库数据的一致性？

    下面单独对  Cache Aside Pattern（旁路缓存模式） 来聊聊。

    Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。

    如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

    1. 缓存失效时间变短（不推荐，治标不治本） ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
    2. 增加cache更新重试机制（常用）： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。
    
11. redis底层数据结构和为什么使用跳表而不使用红黑树原因：https://mp.weixin.qq.com/s/FtfAqXXDef6-bhuGyPDK7w  https://mp.weixin.qq.com/s/JvL2IOUu8mGLfeahHaRBFg   https://mp.weixin.qq.com/s/gRtiSNDCuS0c8nF_Q8Tv9A

    ![https://gitee.com/gu_chun_bo/picture/raw/master/image/20200417125108-879609.png](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200417125108-879609.png)

    1. 简单动态字符串

       ![图片](https://mmbiz.qpic.cn/mmbiz_png/g6hBZ0jzZb0Zb0XiaaR6bGaN80wicXIIP7Diay6tbe99SxEdCbyfMItmJNEDgxQ3iayqmSyEZ8q6IIsibbNQJtP8AcQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

       1. 字符串长度处理，用一个 len 字段记录当前字符串的长度
       2. 内存重新分配，Redis 中会涉及到字符串频繁的修改操作， SDS 实现了两种优化策略1.空间预分配  2.惰性空间释放
       3. 二进制安全，通过len解决

    2. 双端链表

       ![图片](https://mmbiz.qpic.cn/mmbiz_png/g6hBZ0jzZb0Zb0XiaaR6bGaN80wicXIIP70cib2FMf1tT2Tn9ymRyiaTIPAvY0MBsqSCSWOAujwB2tcv4ItkSib1W3g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

       1. 前后节点
       2. 头尾节点：头节点里有 head 和 tail 两个参数
       3. 链表长度：头节点里同时还有一个参数 len，和上边提到的 SDS 里类似

    3. 压缩列表：由于 ziplist 是连续紧凑存储，没有冗余空间，所以插入新的元素需要 realloc 扩展内存，所以如果 ziplist 占用空间太大，realloc 重新分配内存和拷贝的开销就会很大，所以 ziplist 不适合存储过多元素，也不适合存储过大的字符串

       1. ![图片](https://mmbiz.qpic.cn/mmbiz_png/g6hBZ0jzZb0Zb0XiaaR6bGaN80wicXIIP7WIOWyzXHCzPhr4bNJzH3QdYF8R4v27XuIWCqsg8PWGCGg39lTIe3LA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
       2. zlbytes：ziplist所占用的总内存字节数。
       3. Zltail：尾节点到起始位置的字节数。
       4. Zllen：总共包含的节点/内存块数。
       5. Entry：ziplist 保存的各个数据节点，这些数据点长度随意。
       6. Zlend：一个魔数 255，用来标记压缩列表的结束。

    4. 字典

       1. ```java
          typedef struct dict {
              // 类型特定函数
              dictType *type;
              // 私有数据
              void *privdata;
              // 哈希表
              dictht ht[2];
              // rehash 索引
              // 当 rehash 不在进行时，值为 -1
              int rehashidx; /* rehashing not in progress if rehashidx == -1 */
          } dict;
          ```

       2. rehash：

          1. 我们仔细可以看到`dict`结构里有个字段`dictht ht[2]`代表有两个dictht数组。第一步就是为ht[1]哈希表分配空间，大小取决于ht[0]当前使用的情况。
          2. 将保存在ht[0]中的数据rehash(重新计算哈希值)到ht[1]上。
          3. 当ht[0]中所有键值对都迁移到ht[1]后，释放ht[0]，将ht[1]设置为ht[0]，并ht[1]初始化，为下一次rehash做准备。

       3. 渐进式rehash：这就涉及到了渐进式rehash，redis考虑到大量数据迁移带来的cpu繁忙(可能导致一段时间内停止服务)，所以采用了渐进式rehash的方案。步骤如下：

          1. 为ht[1]分配空间，同时持有两个哈希表(一个空表、一个有数据)。
          2. 维持一个技术器rehashidx，初始值0。
          3. 每次对字典增删改查，会顺带将ht[0]中的数据迁移到ht[1],`rehashidx++`(注意：ht[0]中的数据是只减不增的)。
          4. 直到rehash操作完成，rehashidx值设为-1。

    5. 跳跃表

       1. `Redis`之所以使用跳表而不使用红黑树原因如下：
          - 实现简单，相对于红黑树来说，实现更加的简单，不容易出错，代码更加容易维护和调试。
          - 跳表的底层节点有都是通过双向指针相互链接，这和B+树一样，对于范围查找会更加的方便。
          - 跳表的效率和红黑树一样，查找单个Key时间复杂度都是`O(logn)`
          - 跳表更加灵活，可以通过改变索引构建策略，有效的平衡执行效率和内存消耗。

12. 各种数据类型使用的底层结构

    1. String
       1. 当 int 编码保存的值不再是整数，或大小超过了long的范围时，自动转化为raw 
       2. 对于 embstr 编码，由于 Redis 没有对其编写任何的修改程序（embstr 是只读的），在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了44个字节。
       3. embstr 和 raw 编码方式最主要的区别是在内存分配的时候。embstr 编码是专门用于保存短字符串的一种优化编码方式，raw  编码会调用两次内存分配函数来分别创建 redisObject 结构和 sdshdr 结构，而 embstr  编码则通过调用一次内存分配函数来分配一块连续的空间，空间中依次包含redisObject和sdshdr两个结构
    2. Zset
       1. 当有序结合对象同时满足以下两个条件时，对象使用ziplist编码，否则使用skiplist编码
          1. 保存的元素数量小于128
          2. 保存的所有元素长度都小于64字节
       2. ziplist编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。并且压缩列表内的集合元素按分值从小到大的顺序进行排列，小的放置在靠近表头的位置，大的放置在靠近表尾的位置
       3. skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表
    
13. 待定

14. redis持久化

    1. RDB

       1. 什么时候触发？

          1. 如果从节点执行全量复制操作，那么主节点自动执行`bgsave`生成`RDB`文件发送给从节点。（以后将复制的时候会讲到）。
          2. 执行`debug reload`命令重新加载`Redis`时，也会自动触发`save`操作。
          3. 默认情况下执行`shutdown`命令时，如果没有开启`AOF`持久化功能则自动执行`bgsave`。

       2. 默认的配置？

          1. ```java
             save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
             save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
             save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快
             ```

       3.  bgsave执行流程

          1. ![1586178005704](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200406210007-114578.png)
          2. 父进程执行`fork`操作创建子进程，`fork`命令执行过程中父进程会阻塞
          3. 操作系统的**`COW`机制**来进行**数据段页面**的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改（因此，避免在大量写入时做子进程重写操作，这样将导致父进程维护大量页副本，造成内存消耗）。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据

       4. RDB的优缺点

          1. `RDB`的优点：
             1. `RDB`是一个紧凑压缩的二进制文件，代表`Redis`在某个时间点上的数据快照。非常适用于备份，全量复制等场景。比如每6小时执行`bgsave`备份，并把`RDB`文件拷贝到远程机器或者文件系统中（如`hdfs`），用于灾难恢复。
             2. `Redis`加载`RDB`恢复数据远远快于`AOF`的方式。

          2. `RDB`的缺点：
             1. `RDB`方式数据没办法做到实时持久化/秒级持久化。因为`bgsave`每次运行都要执行`fork`操作创建子进程，属于重量级操作，频繁执行成本过高。
             2. `RDB`文件使用特定二进制格式保存，`Redis`版本演进过程中有多个格式的`RDB`版本，存在老版本Redis服务无法兼容新版`RDB`格式的问题。

    2. 

       1. aop 什么时候触发？

          1. 开启`AOF`功能需要在配置文件配置：`appendonly yes`，默认不开启。

       2. aop 默认的配置？

          1. ![https://gitee.com/gu_chun_bo/picture/raw/master/image/20200406221107-431235.png](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200406221107-431235.png)

       3. aop 执行流程

          1. `AOF`的工作流程操作：**命令写入（`append`）、文件同步（`sync`）、文件重写（`rewrite`）、重启加载（`load`）**

             1. 所有的写入命令会追加到`aof_buf`（缓冲区）中。
             2. `AOF`缓冲区根据对应的策略向硬盘做同步动作。
             3. 随着`AOF`文件越来越大，需要定期对`AOF`文件进行重写，达到压缩的目的。
             4. 当`Redis`服务器重启时，可以加载`AOF`文件进行数据恢复。

             ![https://gitee.com/gu_chun_bo/picture/raw/master/image/20200406214619-703862.png](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200406214619-703862.png)

             我们对`everysec`同步策略进行进一步的讨论

             ![1586248933156](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200414220126-329857.png)

             当开启`AOF`持久化时，常用的同步硬盘的策略是`everysec`，用于平衡性能和数据安全性。对于这种方式，`Redis`使用另一条线程每秒执行`fsync`同步硬盘。当系统硬盘资源繁忙时，会造成`Redis`主线程阻塞。

             阻塞流程分析：

             1. 主线程负责写入`AOF`缓冲区。
             2. `AOF`线程负责每秒执行一次同步磁盘操作，并记录最近一次同步时间。
             3. 主线程负责对比上次`AOF`同步时间：
                1. 如果距上次同步成功时间在2秒内，主线程直接返回。
                2. 如果距上次同步成功时间超过2秒，主线程将会阻塞，直到同步操作完成。

       4. aop重写机制

          ![1586184662612](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200414220102-710483.png)

          1. 父进程执行`fork`创建子进程，开销等同于`bgsave`过程。
          2. 主进程`fork`操作完成后，继续响应其他命令。所有修改命令依然写入`AOF`缓冲区并根据`appendfsync`策略同步到**硬盘**，保证原有`AOF`机制正确性。
          3. 由于`fork`操作运用写时复制技术，子进程只能共享`fork`操作时的内存数据。由于父进程依然响应命令，`Redis`使用“`AOF`**重写缓冲区(aof_rewrite_buf)**”保存这部分新数据，防止新`AOF`文件生成期间丢失这部分数据。
          4. 父进程把`AOF`**重写缓冲区(aof_rewrite_buf)**的数据写入到新的`AOF`文件

    3. 混合持久化：将 `rdb` 文件的内容和增量的 `AOF` 日志文件存在一起。这里的 `AOF` 日志不再是全量的日志，而是 **自持久化开始到持久化结束** 的这段时间发生的增量 `AOF` 日志，通常这部分 `AOF` 日志很小：于是在 `Redis` 重启的时候，可以先加载 `rdb` 的内容，然后再重放增量 `AOF` 日志就可以完全替代之前的 `AOF` 全量文件重放，重启效率因此大幅得到提升。

15. redis哨兵模式

    1. 主要命令？

       1. `sentinel monitor <master-name> <ip> <port> <quorum> `：`Sentinel`节点会定期监控主节点，所以从配置上必然也会有所体现，本配置说明`Sentinel`节点要监控的是一个名字叫做<master-name>，ip地址和端口为<ip><port>的主节点。<quorum>代表要判定主节点最终不可达所需要的票数。**但实际上`Sentinel`节点会对所有节点进行监控，但是我们在上面的`Sentinel`节点的配置中没有看到有关从节点和其余`Sentinel`节点的配置，那是因为`Sentinel`节点会从主节点中获取有关从节点以及其余`Sentinel`节点的相关信息**
       
    2. `Redis Sentinel`具有以下几个功能？

       1. **监控：`Sentinel`节点会定期检测`Redis`数据节点、其余`Sentinel`节点是否可达。**
       2. **通知：`Sentinel`节点会将故障转移的结果通知给应用方。**
       3. **主节点故障转移：实现从节点晋升为主节点并维护后续正确的主从关系。**
       4. **配置提供者：后面我们会讲到，在`Redis Sentinel`结构中，客户端在初始化的时候连接的是`Sentinel`节点集合，从中获取主节点信息。**
       5. 同时看到，`Redis Sentinel`包含了若个`Sentinel`节点，这样做也带来了两个好处：

          1. 对于节点的故障判断是由多个`Sentinel`节点共同完成，这样可以有效地防止误判。
          2. `Sentinel`节点集合是由若干个`Sentinel`节点组成的，这样即使个别`Sentinel`节点不可用，整个`Sentinel`节点集合依然是健壮的。

    3. Redis Sentinel客户端基本实现原理

       1. `Redis Sentinel`客户端只有在初始化和切换主节点时需要和`Sentinel`节点集合进行交互来获取主节点信息，所以在设计客户端时需要将`Sentinel`节点集合考虑成配置（相关节点信息和变化）发现服务。当发生故障转移时，客户端便可以收到哨兵的通知，从而完成主节点的切换。具体做法是：利用 `Redis` 提供的发布订阅功能，为每一个哨兵节点开启一个单独的线程，订阅哨兵节点的 + `switch-master` 频道，当收到消息时，重新初始化连接池

    4. 实现原理

       ![1586428999785](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200418181628-819186.png)

       1. Redis Sentinel三个定时监控任务
          1. 每隔10秒，每个`Sentinel`节点会**向主节点和从节点**发送`info`命令获取最新的拓扑结构这个定时任务的作用具体可以表现在三个方面：
             1. 通过向主节点执行`info`命令，获取从节点的信息，这也是为什么`Sentinel`节点不需要显式配置监控从节点。
             2. 当有新的从节点加入时都可以立刻感知出来。
             3. 节点不可达或者故障转移后，可以通过`info`命令实时更新节点拓扑信息。
          2. 每隔2秒，每个`Sentinel`节点会向`Redis`数据节点的**_ sentinel_ ：hello**频道上发送该`Sentinel`节点对于主节点的判断以及当前`Sentinel`节点的信息（如图所示），同时每个`Sentinel`节点也会订阅该频道，来了解其他`Sentinel`节点以及它们对主节点的判断
             1. 发现新的`Sentinel`节点
             2. `Sentinel`节点之间交换主节点的状态，作为后面客观下线以及领导者选举的依据
          3. 每隔1秒，每个`Sentinel`节点会向主节点、从节点、其余`Sentinel`节点发送一条`ping`命令做一次心跳检测，来确认这些节点当前是否可达。
       2. Redis Sentinel主观下线和客观下线
          1. 主观下线：上一小节介绍的第三个定时任务，每个`Sentinel`节点会每隔1秒对主节点、从节点、其他`Sentinel`节点发送`ping`命令做心跳检测，当这些节点超过`down-after-milliseconds`没有进行有效回复，`Sentinel`节点就会对该节点做失败判定，这个行为叫做主观下线
          2. 当`Sentinel`主观下线的节点是主节点时，该`Sentinel`节点会通过`sentinel is-master-down-by-addr`命令向其他`Sentinel`节点询问对主节点的判断，当超过<quorum>个数，`Sentinel`节点认为主节点确实有问题，这时该`Sentinel`节点会做出客观下线的决定
       3. `Sentinel`领导者选举
          1. 假如`Sentinel`节点对于主节点已经做了客观下线，那么是不是就可以立即进行故障转移了？当然不是，实际上故障转移的工作只需要一个`Sentinel`节点来完成即可，所以`Sentinel`节点之间会做一个领导者选举的工作，选出一个Sentinel节点作为领导者进行故障转移的工作。
          2. 每个在线的`Sentinel`节点都有资格成为领导者，**当它确认主节点主观下线时候**，会向其他`Sentinel`节点发送`sentinel is-master-down-by-addr`命令，要求将自己设置为领导者
          3. 收到命令的`Sentinel`节点，如果没有同意过其他`Sentinel`节点的`sentinelis-master-down-by-addr`命令，将同意该请求，否则拒绝。

          4. 如果该`Sentinel`节点发现自己的票数已经大于等于`max（quorum，num（sentinels）/2+1）`，那么它将成为领导者。
       4. Redis Sentinel故障转移
          1. 在从节点列表中选出一个节点作为新的主节点
          2. `Sentinel`领导者节点会对第一步选出来的从节点执行`slaveof no one`命令让其成为主节点。
          3. `Sentinel`领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点，复制规则和`parallel-syncs`参数有关。

          4. `Sentinel`节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点

16. redis主从结构

    1. 主要命令：
       1. psync
          1. 从节点（`slave`）发送`psync`命令给主节点，参数`runId`是当前从节点保存的主节点运行`ID`，如果没有则为默认值，参数`offset`是当前从节点保存的复制偏移量，如果是第一次参与复制则默认值为-1。
          2. 主节点（`master`）根据`psync`参数和自身数据情况决定响应结果：
             1. 如果回复+`FULLRESYNC{runId}{offset}`，那么从节点将触发全量复制
             2. 如果回复`+CONTINUE`，从节点将触发部分复制流程。
    2. 复制过程
       1. 保存主节点（`master`）信息。执行`slaveof`后从节点只保存主节点的地址信息便直接返回，这时建立复制流程还没有开始
       2. 从节点（`slave`）内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接
          1. 从节点会建立一个`socket`套接字，专门用于接受主节点发送的复制命令
       3. 发送`ping`命令。连接建立成功后从节点发送`ping`请求进行首次通信，`ping`请求主要目的如下：检测主从之间网络套接字是否可用。检测主节点当前是否可接受处理命令
          1. 如果发送`ping`命令后，从节点没有收到主节点的`pong`回复或者超时，比如网络超时或者主节点正在阻塞无法响应命令，从节点会断开复制连接，下次定时任务会发起重连
       4. 同步数据集。主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部分操作是耗时最长的步骤（是全量复制，发送的是RDB文件）
       5. 命令持续复制。当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。在命令传播阶段，除了发送写命令，**主从节点还维持着心跳机制**：`PING`和`REPLCONF ACK`
    3. `psync`命令运行需要三个组件支持
       1. **主从节点**各自复制偏移量：主节点和从节点分别维护一个复制偏移量（`offset`），代表的是**主节点向从节点传递的字节数**；
       2. 主节点复制积压缓冲区：复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为1MB，当主节点有连接的从节点（`slave`）时被创建，这时主节点（`master`）响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区，**用于部分复制和复制命令丢失的数据补救**。
       3. **主节点**运行id：每个`Redis`节点启动后都会动态分配一个40位的十六进制字符串作为运行`ID`。
    4. 复制的两种类型
       1. 全量复制
          1. 从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；
          2. 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令
          3. 主节点的bgsave执行完成后，将RDB文件发送给从节点；
          4. 主节点将前述复制缓冲区中的所有写命令发送给从节点
       2. 部分复制
          1. 当从节点（`slave`）正在复制主节点（`master`）时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向主节点要求补发丢失的命令数据，如果主节点的**复制积压缓冲区**中存在这部分数据则直接发送给从节点

17. redis集群

    1. 讲了哨兵，选举Leader，掉线了会发生什么，哨兵之间订阅沟通，主从，集群，脑裂，hash一致性算法（讲了虚拟结点），还有一些不记得了
    2. 主要命令：
       1. `cluster meet{ip}{port}` 加入集群
       2. `cluster replicate{nodeId}`命令让一个节点成为从节点 
    3. 数据分布
       1. 一致性哈希分区（`Distributed Hash Table`）实现思路是为系统中每个节点分配一个`token`，范围一般在0~2^32，这些`token`构成一个哈希环。数据读写执行节点查找操作时，先根据`key`计算`hash`值，然后顺时针找到第一个大于等于该哈希值的`token`节点
       2. 虚拟槽分区：每个节点会负责一定数量的槽，槽是集群内数据管理和迁移的基本单位，槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小
          1. `Redis`虚拟槽分区的特点：
             1. 解耦数据和节点之间的关系，简化了节点扩容和收缩难度。
             2. 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。
             3. 支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。
    4. 通信流程：Gossip 协议的特点是：在节点数量有限的网络中，每个节点都 “随机” 的与部分节点通信 
       1. 大概流程
          1. 集群中的每个节点都会单独开辟一个`TCP`通道，用于节点之间彼此通信，通信端口号在基础端口上加10000
          2. 每个节点在固定周期内通过特定规则选择几个节点发送`ping`消息。
          3. 接收到`ping`消息的节点用`pong`消息作为响应。
       2. 命令：常用的`Gossip`消息可分为：`ping`消息、`pong`消息、`meet`消息、fail消息
          1. `meet`消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，`meet`消息通信正常完成后，接收节点会加入到集群中并进行周期性的`ping`、`pong`消息交换。
          2. `ping`消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送`ping`消息，用于检测节点是否在线和交换彼此状态信息。`ping`消息发送封装了**自身节点和部分其他节点的状态数据**。
          3. `pong`消息：当接收到`ping`、`meet`消息时，作为响应消息回复给发送方确认消息正常通信。`pong`消息内部封装了**自身状态数据**。节点也可以向集群内广播自身的`pong`消息来通知整个集群对**自身状态**进行更新。
          4. `fail`消息：当节点判定集群内**另一个节点**下线时，会向集群内广播一个`fail`消息，其他节点接收到`fail`消息之后把对应节点更新为下线状态。
    5. 扩容和收缩：上层原理：集群伸缩=槽和数据在节点之间的移动
       1. 扩容
          1. 对目标节点发送`cluster setslot{slot}importing{sourceNodeId}`命令，让目标节点准备导入槽的数据。
          2. 对源节点发送`cluster setslot{slot}migrating{targetNodeId}`命令，让源节点准备迁出槽的数据。
          3. 源节点循环执行`cluster getkeysinslot{slot}{count}`命令，获取`count`个属于槽`{slot}`的键。
          4. 在源节点上执行`migrate{targetIp}{targetPort}""0{timeout}keys{keys...}`命令，把获取的键通过流水线（`pipeline`）机制批量迁移到目标节点，批量迁移版本的`migrate`命令在Redis3.0.6以上版本提供，之前的`migrate`命令只能单个键迁移。对于大量`key`的场景，批量键迁移将极大降低节点之间网络`IO`次数。
          5. 重复执行步骤3）和步骤4）直到槽下所有的键值数据迁移到目标节点。
          6. 向集群内所有主节点发送`cluster setslot{slot}node{targetNodeId}`命令，通知槽分配给目标节点。为了保证槽节点映射变更及时传播，需要遍历发送给所有主节点更新被迁移的槽指向新节点。
       
       

